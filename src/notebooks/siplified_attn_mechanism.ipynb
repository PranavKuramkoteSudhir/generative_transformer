{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random statement to test attn mechanism\n",
    "text='Peter Piper picked a peck of pickled peppers. A peck of pickled peppers Peter Piper picked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.data_prep.data_load import CustomDataLoad\n",
    "import tiktoken\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the input convert them into input output batches\n",
    "tk=tiktoken.get_encoding('gpt2')\n",
    "dl=CustomDataLoad(text,4,1,4,False,True,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoad=dl.get_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19727, 33503,  6497,   257]])\n"
     ]
    }
   ],
   "source": [
    "cur=iter(dataLoad)\n",
    "input,target=next(cur)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3684,  1.8227,  0.6509,  ..., -1.3220,  0.4791, -0.5762],\n",
      "        [ 0.8342,  0.0056,  1.9680,  ..., -0.3135,  0.0548,  0.4535],\n",
      "        [ 2.2243, -0.1519,  2.0594,  ..., -0.1665,  2.0036, -0.2256],\n",
      "        ...,\n",
      "        [-0.3729,  0.4732, -0.6389,  ..., -0.8147, -1.3889, -1.3743],\n",
      "        [ 0.6490,  0.7061, -0.5395,  ...,  1.5319, -0.2826, -1.4414],\n",
      "        [-0.1150, -2.9221, -0.5715,  ..., -0.1242, -1.3125,  1.3879]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#embed context to each token of 256 for demonstration add a random embeeding \n",
    "lookup=torch.nn.Embedding(50257,8)#vocab size of tiktoken for gpt2\n",
    "print(lookup.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "#use one input to demostrate attn mechanism\n",
    "data_embed=lookup(input)\n",
    "flattened=data_embed.reshape(4,8)\n",
    "print(flattened.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.7546, 1.2107, 2.6435, 0.3704], grad_fn=<CopySlices>) tensor([0.6936, 0.0545, 0.2283, 0.0235], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#take the target token and perform dot token to identify the similarity between \n",
    "# the two tensors by performing dot product then perform normaliztion to keep velues bw 0 and 1 also use softmax to avoid overflow errors\n",
    "target=flattened[0]\n",
    "attn_score=torch.empty(flattened.shape[0])\n",
    "for i in range(len(flattened)):\n",
    "    attn_score[i]=torch.dot(target,flattened[i])\n",
    "attn_weights=torch.softmax(attn_score,dim=0)\n",
    "print(attn_score,attn_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4206,  0.2713,  0.1409,  0.0018, -0.4920, -0.6390, -0.4650, -0.3945],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Now multiply the dot matrix normalized values to the respective tensors and get the sum of all the vectors \n",
    "# in the input to obtain context\n",
    "attn_vec=torch.zeros(target.shape)\n",
    "for i in range(len(attn_weights)):\n",
    "    attn_vec+=flattened[i]*attn_weights[i]\n",
    "print(attn_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.7546,  1.2107,  2.6435,  0.3704],\n",
      "        [ 1.2107,  4.7110,  0.3374, -2.1224],\n",
      "        [ 2.6435,  0.3374,  6.6409,  1.7895],\n",
      "        [ 0.3704, -2.1224,  1.7895,  6.8002]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# To get a attn matrix we have to do the same for all tokens\n",
    "#the multiplication of each token vector with every other vector can be accomplished by performing matrix multiplication\n",
    "attn_metrics=flattened @ flattened.T\n",
    "print(attn_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.9365e-01, 5.4489e-02, 2.2835e-01, 2.3517e-02],\n",
      "        [2.8918e-02, 9.5797e-01, 1.2076e-02, 1.0319e-03],\n",
      "        [1.7863e-02, 1.7800e-03, 9.7275e-01, 7.6044e-03],\n",
      "        [1.5994e-03, 1.3223e-04, 6.6110e-03, 9.9166e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# To keep the values bw 0 and +1 so we can multiply the weights with the input matrix perform normalization\n",
    "attn_weights=torch.softmax(attn_metrics,dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(attn_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4206,  0.2713,  0.1409,  0.0018, -0.4920, -0.6390, -0.4650, -0.3945],\n",
      "        [-0.0045,  0.7083,  1.3062,  0.7882, -0.1093, -0.3308, -0.2067, -1.1861],\n",
      "        [-1.2075,  0.7773,  0.1682, -0.1800, -0.7364, -1.6026, -0.7583,  0.7726],\n",
      "        [-0.7423, -1.4619,  0.1131, -0.6931,  1.1633, -1.2421, -0.2833,  0.7444]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#now to finally obtain the weights we multipy the scores with the input values\n",
    "final_weights=attn_weights @ flattened\n",
    "print(final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To standardize the process create 3 matrices wq, wk, wv which will help in the processing of input matrix\n",
    "\n",
    "class AttnWeights(torch.nn.Module):\n",
    "    def __init__(self,r,c):\n",
    "        super().__init__()\n",
    "        self.wq=torch.nn.Parameter(torch.rand(r,c))\n",
    "        self.wk=torch.nn.Parameter(torch.rand(r,c))\n",
    "        self.wv=torch.nn.Parameter(torch.rand(r,c))\n",
    "\n",
    "    def forward(self,input):\n",
    "        wq_input=input @ self.wq\n",
    "        wk_input=input @ self.wk\n",
    "        wv_input=input @ self.wv\n",
    "\n",
    "        attn_score= wq_input @ wk_input.H\n",
    "        attn_weights=torch.softmax((attn_score/(wk_input.shape[-1]**0.5)),dim=-1)\n",
    "        context_vec=attn_weights @ wv_input\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0328, -2.9521, -2.4829, -2.2293, -1.8444, -0.7724, -2.0626, -1.0723],\n",
       "        [ 0.8618, -0.8292, -0.3906,  0.3141, -0.1706,  0.9134, -0.1894, -0.0228],\n",
       "        [-1.0589, -2.9283, -2.4482, -2.1981, -1.8292, -0.7584, -2.0226, -1.0394],\n",
       "        [-1.1184, -2.8131, -2.3032, -2.1286, -1.7683, -0.7826, -1.9099, -0.9156]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aw=AttnWeights(8,8)\n",
    "aw.forward(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
